{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5\n",
    "\n",
    "- Today we will review two more topics:\n",
    "    1. Text analysis\n",
    "    2. Machine learning\n",
    "    3. Webscraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 5.1: Machine Learning\n",
    "\n",
    "- This lecture has been modified from a tutorial at [pythonforengineers.com](https://www.pythonforengineers.com/machine-learning-for-complete-beginners/).\n",
    "- **If you have any questions over the course of this lecture, please post them to the 'Day 5 Lecture Questions' assignment on the Canvas course page.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 5.1: Machine Learning\n",
    "\n",
    "- Steps:\n",
    "    1. Gather data\n",
    "        - Web scraping\n",
    "        - Compiling text data\n",
    "        - Conduct survey\n",
    "    2. Clean data\n",
    "    3. **Prepare data for machine learning**\n",
    "    4. **Run ML algorithms**\n",
    "    5. **Test model**\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "- For this lecture we have some statistics about the survivors and mortalities of the titanic ship wreck.\n",
    "- We will load in the regular packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>3rd</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Miss Katie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Millet, Mr Francis Davis</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>East Bridgewater, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-249</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>557</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Sjostedt, Mr Ernst Adolf</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Sault St Marie, ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>McCaffry, Mr Thomas Francis</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-292</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1233</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Strilic, Mr Ivan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived                         name   age     embarked  \\\n",
       "0        999    3rd         1         McCarthy, Miss Katie   NaN          NaN   \n",
       "1        180    1st         0     Millet, Mr Francis Davis  65.0  Southampton   \n",
       "2        557    2nd         0     Sjostedt, Mr Ernst Adolf  59.0  Southampton   \n",
       "3        175    1st         0  McCaffry, Mr Thomas Francis  46.0    Cherbourg   \n",
       "4       1233    3rd         0             Strilic, Mr Ivan   NaN          NaN   \n",
       "\n",
       "              home.dest room ticket  boat     sex  \n",
       "0                   NaN  NaN    NaN   NaN  female  \n",
       "1  East Bridgewater, MA  NaN    NaN  -249    male  \n",
       "2    Sault St Marie, ON  NaN    NaN   NaN    male  \n",
       "3         Vancouver, BC  NaN    NaN  -292    male  \n",
       "4                   NaN  NaN    NaN   NaN    male  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"titanic_lecture.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit the data.\n",
    "- Now we can look at some of our data and change it such that it is suitable for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row.names', 'pclass', 'survived', 'name', 'age', 'embarked',\n",
       "       'home.dest', 'room', 'ticket', 'boat', 'sex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to grab the median age and fill in the missing data with this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median age is 29.0\n"
     ]
    }
   ],
   "source": [
    "median_age = data['age'].median()\n",
    "print(\"Median age is {}\".format(median_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29.0\n",
       "1    65.0\n",
       "2    59.0\n",
       "3    46.0\n",
       "4    29.0\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'].fillna(median_age, inplace = True)\n",
    "data['age'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rid of string values.\n",
    "- We will replace text representation of the ticket class each passenger had with numeric values.\n",
    "- We will replace `female` and `male` with numeric indicators where 0 == Female and 1 == Male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data[\"pclass\"].replace(\"3rd\", 3, inplace = True)\n",
    "data[\"pclass\"].replace(\"2nd\", 2, inplace = True)\n",
    "data[\"pclass\"].replace(\"1st\", 1, inplace = True)\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Miss Katie</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Millet, Mr Francis Davis</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>East Bridgewater, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>557</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sjostedt, Mr Ernst Adolf</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Sault St Marie, ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>McCaffry, Mr Thomas Francis</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1233</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Strilic, Mr Ivan</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names  pclass  survived                         name   age  \\\n",
       "0        999       3         1         McCarthy, Miss Katie  29.0   \n",
       "1        180       1         0     Millet, Mr Francis Davis  65.0   \n",
       "2        557       2         0     Sjostedt, Mr Ernst Adolf  59.0   \n",
       "3        175       1         0  McCaffry, Mr Thomas Francis  46.0   \n",
       "4       1233       3         0             Strilic, Mr Ivan  29.0   \n",
       "\n",
       "      embarked             home.dest room ticket  boat  sex  \n",
       "0          NaN                   NaN  NaN    NaN   NaN    0  \n",
       "1  Southampton  East Bridgewater, MA  NaN    NaN  -249    1  \n",
       "2  Southampton    Sault St Marie, ON  NaN    NaN   NaN    1  \n",
       "3    Cherbourg         Vancouver, BC  NaN    NaN  -292    1  \n",
       "4          NaN                   NaN  NaN    NaN   NaN    1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sex\"] = np.where(data[\"sex\"] == \"female\", 0, 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "- For most calculations we are going to need X and Y variables in separate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived\n",
       "0         1\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[[\"survived\"]].copy()\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass   age  sex\n",
       "0       3  29.0    0\n",
       "1       1  65.0    1\n",
       "2       2  59.0    1\n",
       "3       1  46.0    1\n",
       "4       3  29.0    1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[[\"pclass\", \"age\", \"sex\"]].copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting variables\n",
    "- An important part of machine learning is [selecting your variables](https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/).\n",
    "    - Here we selected the class the passenger was in, age and sex.\n",
    "    - Variables such as an individuals names is random and unlikely to have any predictive power.\n",
    "- In machine learning our variables are 'features' of the data. By selecting only the relevant features we reduce the noise which comes from irrelevant data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods of feature selection\n",
    "- You can use theoretical explanations to select features.\n",
    "- You can use the process of elimination during by running with all the data and then excluding feature-by-feature and observing changes in performance.\n",
    "    - Alternatively you can start with one variable and rerun each time adding a new variable and explore changes in performance.\n",
    "- You can filter using various techiniques:\n",
    "    - Use Chi-Square Test to test the independence of two events.\n",
    "    - You can remove all features who have zero variance with your outcome.\n",
    "- You can explore the best features while running your models:\n",
    "    - Lasso \n",
    "    - Ridge regression\n",
    "    - Elastic net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test data.\n",
    "\n",
    "- One of the most important part of machine learning is ascertaining how well a certain model is performing.\n",
    "    - To do this we slit our dataset so that roughly 70% is used for training.\n",
    "        - We take the training data and we run a model on this data. The model is then saved.\n",
    "        - Our models learn about our data by establishing coefficients.\n",
    "    - The other 30% is our testing data.\n",
    "        - We take the model which we have created and we can see how well it performs on 'out of sample' predictions.\n",
    "        - The model is tested for accuracy by seeing how it predicts data that it was not trained on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test data.\n",
    "\n",
    "- This whole structure is meant to prevent overfitting the data.\n",
    "    - For example you may have a very large dataset with a lot of variables so you create a model based on those factors.\n",
    "        - However, once you go to a smaller dataset and apply the same model you may find it performs very poorly.\n",
    "- With our training and test data we can gaue how well a specific model performs and compare it to other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pclass   age  sex\n",
      "93        3  29.0    1\n",
      "268       3  29.0    1\n",
      "335       3  29.0    1\n",
      "340       3  22.0    0\n",
      "598       2  34.0    1\n",
      "     survived\n",
      "93          0\n",
      "268         0\n",
      "335         0\n",
      "340         1\n",
      "598         0\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.model_selection\n",
    "\n",
    "X_train, X_test, Y_train, Y_test   = sk.model_selection.train_test_split(X, Y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "print(X_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the data\n",
    "- We will try several different types of models to see which one predicts best who survived on the Titanic.\n",
    "- We don't have the time to do an in-depth exploration into the math behind each of the models I present.\n",
    "    - I will provide a link for each model which gives you an explanation of the model at hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (statsmodel)\n",
    "- Yesterday we used the `statsmodel` package to to OLS, however, because we are looking at a binary variable (1== survive; 0==died) we will look at a logistic regression.\n",
    "- We will look at another package, but the statsmodel has nice summary tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.508727\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               survived   No. Observations:                  439\n",
      "Model:                          Logit   Df Residuals:                      436\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 13 Jun 2020   Pseudo R-squ.:                  0.2078\n",
      "Time:                        15:05:21   Log-Likelihood:                -223.33\n",
      "converged:                       True   LL-Null:                       -281.90\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.654e-26\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "pclass        -0.3704      0.093     -3.975      0.000      -0.553      -0.188\n",
      "age            0.0364      0.007      5.052      0.000       0.022       0.051\n",
      "sex           -1.9026      0.234     -8.115      0.000      -2.362      -1.443\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels as sm\n",
    "\n",
    "lm = sm.discrete.discrete_model.Logit(endog = Y_train, exog = X_train, data = data).fit()\n",
    "print(lm.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `statsmodel`\n",
    "- `statsmodel` is not specifically for making predictions so there is no inherent way to see how well it performed, however, it's quite easy to calculate.\n",
    "- Even though we ran a Logit model the `logit` attribute of `statsmodel` still only returns a probablity of survival, so we round this value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192     True\n",
       "265     True\n",
       "101     True\n",
       "625     True\n",
       "523     True\n",
       "       ...  \n",
       "304     True\n",
       "488     True\n",
       "203     True\n",
       "196     True\n",
       "352    False\n",
       "Length: 217, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction rate of success is: 0.7788018433179723\n"
     ]
    }
   ],
   "source": [
    "predictions = lm.predict(X_test)\n",
    "print('The prediction rate of success is:',sum(round(predictions) == Y_test['survived'])/len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we ran ols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2 = sm.api.formula.ols(\"survived ~ C(pclass) + age + sex\", data = data).fit()\n",
    "print(lm2.summary())\n",
    "predictions2 = lm2.predict(X_test)\n",
    "results = []\n",
    "results = ['OLS Prediction rate of success: {}%'.format(sum(round(predictions2) == Y_test['survived'])/len(predictions2) * 100)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (sklearn)\n",
    "- `sklearn` *is* a package created for prediction.\n",
    "- The tradeoff here is there is no clean way to look at a summary of our regression.\n",
    "    - We can look at coefficients and R-squared values separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1164483 , -0.03100704, -2.19867651]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Different coefficients?\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train.values.ravel())\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37044427,  0.03639955, -1.90261196]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn off regularization and do not fit the intercepts!\n",
    "logreg2 = sk.linear_model.LogisticRegression(C=1e9,fit_intercept = False)\n",
    "logreg2.fit(X_train, Y_train.values.ravel())\n",
    "logreg2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8064516129032258"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manual\n",
    "y_pred = logreg.predict(X_test)\n",
    "sum(y_pred == Y_test['survived'])/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR Prediction rate of success: 80.64516129032258%']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#built-in attributes\n",
    "results = []\n",
    "\n",
    "logreg.score(X_test,Y_test)\n",
    "results.append('LR Prediction rate of success: {}%'.format(logreg.score(X_test,Y_test)*100))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "- Random forests are a type of [decision tree](https://www.youtube.com/watch?v=DCZ3tsQIoGU&feature=youtu.be&t=389) which is a method of classifying data.\n",
    "- [Decision trees](https://www.analyticsvidhya.com/blog/2020/05/decision-tree-vs-random-forest-algorithm/) take all the data (all observations and variables/features).\n",
    "\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/05/rfc_vs_dt11.png\" width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "- [RF algorithms](https://www.youtube.com/watch?v=D_2LkhMJcfY) is one of the most popular types of decision trees.\n",
    "- The difference between random forest and your general decision tree is that random forest randomly selects a subset of observations and varaibles and build multiple decision trees.\n",
    "    - Trees are built independently.\n",
    "    - From these multiple analyses, the outcomes are averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR Prediction rate of success: 80.64516129032258%',\n",
       " 'RF Prediction rate of success: 77.41935483870968%']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train.values.ravel())\n",
    "results.append(('RF Prediction rate of success: {}%'.format(rf.score(X_test, Y_test) * 100)))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting\n",
    "- Gradient boosting is another type of decision tree.\n",
    "- Rather than averaging out the results at the end, gradient boosting is iterative.\n",
    "    - Each tree learns from the last and tries to make corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR Prediction rate of success: 80.64516129032258%',\n",
       " 'RF Prediction rate of success: 77.41935483870968%',\n",
       " 'GBM Prediction rate of success: 78.80184331797236%']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "GBM = GradientBoostingClassifier()\n",
    "GBM.fit(X_train, Y_train.values.ravel())\n",
    "results.append('GBM Prediction rate of success: {}%'.format(GBM.score(X_test,Y_test)*100))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### SVM\n",
    "- [Support vector machines](https://www.youtube.com/watch?time_continue=2&v=Y6RRHw9uN9o) work by drawing a boundary line (hyper plane) between our training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR Prediction rate of success: 80.64516129032258%',\n",
       " 'RF Prediction rate of success: 77.41935483870968%',\n",
       " 'GBM Prediction rate of success: 78.80184331797236%',\n",
       " 'SVM Prediction rate of success: 68.20276497695853%']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm =SVC()\n",
    "svm.fit(X_train,Y_train.values.ravel())\n",
    "results.append(('SVM Prediction rate of success: {}%'.format(svm.score(X_test, Y_test) * 100)))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "- The [Naive Bayes Classifier](https://www.youtube.com/watch?v=CPqOCI0ahss) relies on Bayes Theorem.\n",
    "    - $ P(A \\mid B) = \\frac{P(B \\mid A) \\, P(A)}{P(B)} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR Prediction rate of success: 80.64516129032258%',\n",
       " 'RF Prediction rate of success: 77.41935483870968%',\n",
       " 'GBM Prediction rate of success: 78.80184331797236%',\n",
       " 'SVM Prediction rate of success: 68.20276497695853%',\n",
       " 'NB Prediction rate of success: 76.036866359447%']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb= GaussianNB()\n",
    "nb.fit(X_train, Y_train.values.ravel())\n",
    "results.append('NB Prediction rate of success: {}%'.format(nb.score(X_test,Y_test)*100))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors\n",
    "\n",
    "- [KNN](https://www.youtube.com/watch?v=MDniRwXizWo) is a non-parametric method which looks at the 'k' number of closest examples so those who are closest together are similarly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR Prediction rate of success: 80.64516129032258%',\n",
       " 'RF Prediction rate of success: 77.41935483870968%',\n",
       " 'GBM Prediction rate of success: 78.80184331797236%',\n",
       " 'SVM Prediction rate of success: 68.20276497695853%',\n",
       " 'NB Prediction rate of success: 76.036866359447%',\n",
       " 'KNN Prediction rate of success: 70.96774193548387%']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knear =  KNeighborsClassifier()\n",
    "knear.fit(X_train, Y_train.values.ravel())\n",
    "results.append('KNN Prediction rate of success: {}%'.format(knear.score(X_test,Y_test)*100))\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
